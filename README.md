# CODSOFT :TASK 1 :


# üé¨ Movie Genre Classification

This project focuses on building a machine learning model that can classify the **genre of a movie** based on its **title and plot description**. The system uses natural language processing (NLP) techniques and classic machine learning algorithms to predict genres effectively.

---

## üß† Task

**Goal:** Predict the genre of a movie from its plot summary and title using machine learning models.

---

## üìÇ Dataset

The dataset contains the following columns:

- `TITLE`: The title of the movie.
- `DESCRIPTION`: A brief plot summary of the movie.
- `GENRE`: The target label ‚Äî the movie's genre.

Train and test CSV files are used:
- `output_dataset.csv` ‚Äì for training/validation.
- `out_dataset.csv` ‚Äì for testing.
- `outsol_dataset.csv` ‚Äì ground truth for test set.

---

## ‚öôÔ∏è Models Used

1. **Naive Bayes (GaussianNB)**
2. **Logistic Regression**
3. **Support Vector Machine (SVM - LinearSVC)**

TF-IDF vectorization was applied to the combined movie title and description to extract textual features.

---

## üîÅ Workflow

1. **Preprocessing:**
   - Combined `TITLE` and `DESCRIPTION` into a single `text` column.
   - Applied TF-IDF vectorization (max features = 5000).

2. **Training:**
   - Models were trained on 80% of the data and validated on 20%.

3. **Evaluation:**
   - Accuracy scores were computed for each model on both training and test splits.
   - Final predictions were compared with the ground truth labels.

---

## üìä Results

| Model               | Train Accuracy | Test Accuracy |
|--------------------|----------------|---------------|
| GaussianNB          | 0.656          | 0.419         |
| Logistic Regression | 0.986          | 0.825         |
| Linear SVM          | 1.000          | 0.826         |

> The SVM and Logistic Regression models significantly outperformed Naive Bayes in accuracy.

---


## üöÄ How to Run

1. Clone this repository.
2. Install required Python packages:
   ```bash
   pip install pandas numpy scikit-learn
   ```
3. Place the dataset files in the same directory.
4. Run the Python script:
   ```bash
   python cstask1sc2_mvgenre.py
   ```

---

## üìà Final Test Evaluation

A separate test set was evaluated using the Logistic Regression model. Accuracy is printed at the end of the script along with actual vs. predicted genre comparison.

---

## üìå Notes

- Ensure that the dataset file paths are correctly set before running the script.
- This project can be further improved by experimenting with deep learning models like LSTM or transformers.

---

## üì¨ Contact

For any queries or suggestions, feel free to reach out!

--- 
Based on the script and video you provided for **Task 2: Credit Card Fraud Detection**, here's a fully prepared `README.md` section that you can copy and paste into your existing README:

---
# CODSOFT :TASK 2 :


# üí≥ Credit Card Fraud Detection

This project involves detecting fraudulent credit card transactions using machine learning models. The dataset contains transactional data and the goal is to classify each transaction as either **fraudulent** or **legitimate**.

---

## üß† Task

**Goal:** Build a model that detects fraudulent credit card transactions by analyzing patterns in the transaction features. Algorithms such as Logistic Regression, Decision Trees, or Random Forests can be applied for classification.

---

## üìÇ Dataset

The dataset used in this task includes:

- `fraudTrain.csv` ‚Äì training set with labeled transactions.
- `fraudTest.csv` ‚Äì test set with labeled transactions.

Key columns include:
- Transaction amount, category, merchant, time, and location.
- Target column: `is_fraud` (1 = Fraudulent, 0 = Legitimate)

---

## ‚öôÔ∏è Model Used

- **Random Forest Classifier**

Data preprocessing steps included:
- Dropping irrelevant columns such as `trans_num`, `unix_time`, and personal names.
- Encoding categorical variables with `LabelEncoder`.
- Extracting `hour`, `day`, and `month` from the transaction timestamp.
- Standardizing numerical features using `StandardScaler`.

---

## üîÅ Workflow

1. **Preprocessing:**
   - Date-time features extracted and redundant columns dropped.
   - Categorical data encoded.
   - Data normalized using standard scaling.

2. **Training:**
   - Model trained using `RandomForestClassifier(n_estimators=100)`.

3. **Evaluation:**
   - Accuracy, confusion matrix, and classification report computed on the test set.

---

## üìä Results

| Metric         | Value        |
|----------------|--------------|
| Accuracy       | 0.974        |
| Precision (1)  | 0.90         |
| Recall (1)     | 0.87         |
| F1-Score (1)   | 0.88         |

> The model performs very well with high accuracy and strong fraud detection performance

---

## üöÄ How to Run

1. Clone this repository.
2. Install required Python packages:
   ```bash
   pip install pandas numpy scikit-learn matplotlib seaborn
   ```
3. Make sure the dataset files (`fraudTrain.csv`, `fraudTest.csv`) are in the working directory.
4. Run the Python script:
   ```bash
   python csTASK2_ccfraud_script.py
   ```

---

## üìå Notes

- For better fraud detection, consider techniques like SMOTE for handling class imbalance, or try neural network models for more advanced learning.
- Real-time fraud detection systems often require model deployment and integration with transaction streams.

---

## üì¨ Contact

For feedback or collaboration, feel free to connect!

---
Based on your script and video for **Task 3: Customer Churn Prediction**, here is a ready-to-use `README.md` section that summarizes your work and can be pasted directly into your GitHub documentation.

---

# CODSOFT :TASK 3 :

# üîÅ Customer Churn Prediction

This project focuses on building a machine learning model to predict customer churn for a subscription-based service. By analyzing customer behavior and demographic features, the system aims to identify users who are likely to stop using the service.

---

## üß† Task

**Goal:** Predict whether a customer will churn using historical data, including features such as tenure, credit score, account balance, and geographic/demographic attributes.

---

## üìÇ Dataset

Dataset used: `Churn_Modelling.csv`

Key columns:
- `CreditScore`, `Geography`, `Gender`, `Age`, `Tenure`, `Balance`, `NumOfProducts`, `HasCrCard`, `IsActiveMember`, `EstimatedSalary`
- Target column: `Exited` (1 = Churned, 0 = Active)

---

## ‚öôÔ∏è Models Used

Three models were trained and evaluated:

1. **Logistic Regression**
2. **Random Forest Classifier**
3. **XGBoost Classifier**

Key preprocessing steps:
- Dropped irrelevant identifiers: `RowNumber`, `CustomerId`, `Surname`
- Encoded categorical variables (`Geography`, `Gender`) using one-hot encoding
- Scaled numerical columns using `StandardScaler`
- Applied class weighting to handle class imbalance

---

## üîÅ Workflow

1. **Data Preprocessing**
2. **Training with Class Weighting**
3. **Model Evaluation**:
   - Accuracy
   - ROC AUC Score
   - Precision, Recall, and F1-Score
4. **Precision-Recall Curve Analysis**
5. **Threshold Optimization for XGBoost**
6. **Feature Importance (XGBoost)**

---

## üìä Results

### Test Set Performance

| Model              | Accuracy | ROC AUC | Optimized F1 (XGB) |
|--------------------|----------|---------|--------------------|
| Logistic Regression| 0.81     | 0.85    | ‚Äî                  |
| Random Forest      | 0.86     | 0.91    | ‚Äî                  |
| XGBoost            | 0.87     | 0.92    | 0.84               |

> The XGBoost model provided the best performance overall, especially after optimizing the decision threshold based on F1-score.

---


## üöÄ How to Run

1. Clone this repository.
2. Install required dependencies:
   ```bash
   pip install pandas numpy scikit-learn matplotlib xgboost
   ```
3. Ensure `Churn_Modelling.csv` is placed in the script directory.
4. Run the script:
   ```bash
   python TASK3_s2_customer_churn.py
   ```

---

## üìå Notes

- This project uses **XGBoost's `scale_pos_weight`** to handle class imbalance and optimizes the decision threshold for improved F1-score.
- Consider integrating SHAP or LIME for better interpretability of predictions in production.

---

## üì¨ Contact

For questions, suggestions, or contributions, feel free to reach out!

---

Based on your script, task description, and video for **Task 4: Spam SMS Detection**, here is a polished and detailed `README.md` section you can paste directly into your GitHub repo:

---

# CODSOFT :TASK 4 :

# üì© Spam SMS Detection

This project focuses on building a machine learning model to classify SMS messages as **spam** or **legitimate (ham)**. It applies natural language processing (NLP) techniques such as TF-IDF and uses multiple classifiers to evaluate model performance.

---

## üß† Task

**Goal:** Build an AI model that can classify SMS messages as spam or legitimate using textual data. Algorithms such as Naive Bayes, Logistic Regression, or Support Vector Machines are used for this classification task.

---

## üìÇ Dataset

Dataset used: [`spam.csv`](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)

Key columns:
- `v1`: The label (`spam` or `ham`)
- `v2`: The actual message text

The dataset is preprocessed as follows:
- Renamed `v1` to `label` and `v2` to `text`
- Labels encoded (`spam` ‚Üí 1, `ham` ‚Üí 0)
- Lowercased and stripped punctuation

---

## ‚öôÔ∏è Models Used

1. **Multinomial Naive Bayes**
2. **Logistic Regression**
3. **Support Vector Machine (Linear Kernel)**

All models use **TF-IDF vectorization** with `max_features=5000` to transform text into numerical feature vectors.

---

## üîÅ Workflow

1. **Text Preprocessing**
   - Convert to lowercase
   - Remove punctuation
   - Token normalization

2. **Vectorization**
   - TF-IDF applied to message text

3. **Model Training**
   - Data split: 80% training, 20% testing
   - Models evaluated using:
     - Accuracy
     - Precision / Recall / F1 (for spam class)
     - Confusion Matrix

4. **Results Aggregation**
   - All results compiled in a comparison DataFrame

---

## üìä Results

| Metric              | Naive Bayes | Logistic Regression | SVM         |
|---------------------|-------------|----------------------|-------------|
| Accuracy            | 0.9780      | 0.9810               | 0.9810      |
| Precision (Spam)    | 0.9634      | 0.9756               | 0.9756      |
| Recall (Spam)       | 0.9151      | 0.9151               | 0.9151      |
| F1-Score (Spam)     | 0.9387      | 0.9444               | 0.9444      |
| Confusion Matrix    | [[949   0],<br> [ 20 146]] | [[949   0],<br> [ 14 152]] | [[949   0],<br> [ 14 152]] |

> Logistic Regression and SVM achieved the highest overall accuracy and F1-score, showing strong performance in spam classification.

---

## üé• Output Demo

A video demonstrating data loading, training, evaluation, and result comparison is available below:

üìΩÔ∏è **[Watch the Demo Video](task4_spamSMSdetection_output.mp4)**

> ‚ö†Ô∏è If this file is too large to upload directly to GitHub, consider uploading it to YouTube or Google Drive and updating the link accordingly.

---

## üöÄ How to Run

1. Clone the repository.
2. Install required packages:
   ```bash
   pip install pandas scikit-learn
   ```
3. Place `spam.csv` in the working directory.
4. Run the Python script:
   ```bash
   python task4_spam_sms_detection.py
   ```

---

## üìå Notes

- Consider using **n-grams** or **word embeddings** (e.g., Word2Vec or GloVe) to improve results.
- For deployment, wrap the model in a web or mobile application with live message scanning.

---

## üì¨ Contact

For feedback or collaboration, feel free to reach out!

---
